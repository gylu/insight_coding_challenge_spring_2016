{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'b', 'b', 'c']\n",
      "['w', 'x', 'y', 'z']\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-ebe2942526ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'b'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "a=['a','b','b','c']\n",
    "b=['w','x','y','z']\n",
    "print(a)\n",
    "print(b)\n",
    "#for letter in a:\n",
    "#    if (letter=='c'):\n",
    "#       print(a.index(letter))\n",
    "\n",
    "for index in range(len(a)):\n",
    "    if a[index]=='b':\n",
    "        del a[index]\n",
    "        del b[index]\n",
    "        \n",
    "print(a)\n",
    "print(b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'b', 'b', 'c']\n",
      "['w', 'x', 'y', 'z']\n",
      "['b', 'b', 'c']\n",
      "['a', 'b', 'b', 'c']\n",
      "['w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "a=['a','b','b','c']\n",
    "b=['w','x','y','z']\n",
    "c=[entry for entry in a if entry !='a']\n",
    "print(a)\n",
    "print(b)\n",
    "print(c)\n",
    "for letter in a:\n",
    "    if (letter=='c'):\n",
    "        del letter\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[789, ['e', 'f']], [788, ['e', 'f']]]\n"
     ]
    }
   ],
   "source": [
    "c=[[123,['a','b']],[456,['e','f']],[789,['e','f']],[788,['e','f']]]\n",
    "['a','b'] in c\n",
    "d=[entry for entry in c if entry[0] > 789-60]\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('ht2', 'ht1'), ('ht2', 'ht3'), ('ht1', 'ht3')]\n",
      "('ht2', 'ht1')\n",
      "None\n",
      "('ht2', 'ht3')\n",
      "None\n",
      "('ht1', 'ht3')\n",
      "None\n",
      "[('ht2', 'ht1'), ('ht2', 'ht3'), ('ht1', 'ht3')]\n",
      "[['ht1', 'ht2'], ['ht2', 'ht3'], ['ht1', 'ht3']]\n"
     ]
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "listOfHashtags=['ht2','ht1','ht3']\n",
    "new_list_of_edges=list(combinations(listOfHashtags,2))\n",
    "print (new_list_of_edges)\n",
    "for entry in new_list_of_edges:\n",
    "    print(entry)\n",
    "    listEntry=list(entry)\n",
    "    print(listEntry.sort())\n",
    "print (new_list_of_edges)\n",
    "#this works\n",
    "output=[sorted(entry) for entry in new_list_of_edges]\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['ab', 'xx'],\n",
       " ['ac', 'xx'],\n",
       " ['aa', 'xx'],\n",
       " ['ab', 'ac'],\n",
       " ['aa', 'ab'],\n",
       " ['aa', 'ac']]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_edge_entries(listOfHashtags):\n",
    "    new_list_of_tuple_edges=list(combinations(listOfHashtags,2))\n",
    "    new_list_of_edges = [sorted(element) for element in new_list_of_tuple_edges]\n",
    "    return new_list_of_edges\n",
    "\n",
    "x=['xx','ab','ac','aa']\n",
    "create_edge_entries(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-50-6a217dd1967a>, line 77)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-50-6a217dd1967a>\"\u001b[0;36m, line \u001b[0;32m77\u001b[0m\n\u001b[0;31m    global EDGE_LIST = [entry for entry in EDGE_LIST if entry[0] > NEWEST_TIMESTAMP-60] #3 Delete edges older than 60s\u001b[0m\n\u001b[0m                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import json #use for json parser\n",
    "from itertools import combinations #used to run combinations (order doesn't matter)\n",
    "import time #needed to deal with timestamps\n",
    "\n",
    "#Note: From the way run.sh is called:\n",
    "#print(sys.argv[0]) #will be the name of this script: average_degree.py\n",
    "#print(sys.argv[1]) #will be ./tweet_input/tweets.txt \n",
    "#print(sys.argv[2]) #Will be ./tweet_output/output.txt\n",
    "\n",
    "#todo replace:\n",
    "# sys_argv0 replace for sys.argv[0]\n",
    "# sys_argv1\n",
    "# sys_argv2\n",
    "sys_argv1 = './tweet_input/tweets.txt'\n",
    "sys_argv2 = './tweet_output/output.txt'\n",
    "#todo:\n",
    "#remove tweet_input/tweets.txt from the gitignore\n",
    "\n",
    "#1.     Get tweets:\n",
    "#1a     If it's a rate limiting message, ignore it\n",
    "\n",
    "#2.     Check timestamp:\n",
    "#2a     If timestamp is older than 60s, delete tweet, jump to call calc_average_degree() to end\n",
    "#2b     If timestamp is newer than newest, update newest_timestamp value\n",
    "\n",
    "#3      Delete edges that are older than 60 seconds\n",
    "\n",
    "#4      Find hashtags:\n",
    "#4a     If tweet has 2 or most hashtags, check and remove all duplicates\n",
    "#4b     If only 0 or 1 hashtag remains, discard tweet, jump to call calc_average_degree()\n",
    "\n",
    "#5      Create edge entries: (If tweet has 2 or more valid hashtags, create edge entries)\n",
    "#5a     Use the combination package that was imported. Eg: list(combinations(['hashtag1','hashtag2','hashtag3'],2)). This outputs a list of tuples.\n",
    "#5b     Sort each edge entry alphabetically so that we don't have the check the reverse. Do this by converting each tuple into a list and sorting\n",
    "\n",
    "#6      Insert each new edge entry into edge_list:\n",
    "#6a     Check that the edge (and the reverse) doesn't already exist, if it does, remove the older edge\n",
    "\n",
    "#7      call calc_average_degree()\n",
    "#7a     concatenate the 2 columns of nodes in the edge_list, and sum\n",
    "#7b     remove duplicates to get the number of nodes\n",
    "\n",
    "\n",
    "\n",
    "#Implementation of the above outline:\n",
    "\n",
    "NEWEST_TIMESTAMP=0.00; #global vairable\n",
    "EDGE_LIST=[] #of the format: [[timestamp1,['hashtagX1','hashtagY1']], [timestamp2,['hashtagX2','hashtagY2']], ...etc]\n",
    "\n",
    "#clear out old ./tweet_output/tweets.txt file\n",
    "if os.path.exists(sys_argv2):\n",
    "    os.remove(sys_argv2) #note that the location is based on where run.sh was called\n",
    "\n",
    "outputFile = open(sys_argv2, 'a+')\n",
    "\n",
    "#1. Get tweets\n",
    "\n",
    "#future optimization: this may be able to be optimized to process one-at-a-time as each json object line in the text file is read\n",
    "tweets = []\n",
    "for line in open(sys_argv1, 'r'):\n",
    "    line_json_parsed = json.loads(line)\n",
    "    if 'created_at' in line_json_parsed: #1a. Ignore the rate limiting messages\n",
    "        tweets.append(line_json_parsed)\n",
    "        # #Example usage of the tweets array that examples the 248th tweet in the file\n",
    "        # tweets[248] # fetches a tweet\n",
    "        # tweets[248]['created_at'] # fetches timestamp of tweet, returns in the format of \"Wed Aug 29 17:12:58 +0000 2012\"\n",
    "        # tweets[248]['entities']['hashtags'] # fetches all hashtags of a tweet\n",
    "        # tweets[248]['entities']['hashtags'][1] # fetches individual hashtag of a tweet\n",
    "        # tweets[248]['entities']['hashtags'][1]['text'] # fetch individual hashtag text of a tweet\n",
    "        # len(tweets[248]['entities']['hashtags']) #tells you how many hashtags the tweet had\n",
    "\n",
    "for tweet in tweets:\n",
    "    tweet_timestamp = time.mktime(time.strptime(tweet['created_at'],\"%a %b %d %H:%M:%S +0000 %Y\")) #followed this http://stackoverflow.com/questions/18604755/twitter-created-at-convert-epoch-time-in-python\n",
    "    if (check_and_update_timestamp(tweet_timestamp)):     #2. Check timestamp: #note that this created_at field is always utc time\n",
    "        global EDGE_LIST = [entry for entry in EDGE_LIST if entry[0] > NEWEST_TIMESTAMP-60] #3 Delete edges older than 60s\n",
    "        validHashtags=find_hashtags(tweet)         #4      Find hashtags:\n",
    "        if(len(validHashtags)>1):\n",
    "            new_list_of_edges=create_edge_entries(validHashtags);             #5      Create edge entries:\n",
    "            update_edge_list(new_list_of_edges,tweet_timestamp);\n",
    "    calc_average_degree();             #6      Insert each new edge entry into edge_list:\n",
    "\n",
    "outputFile.close();\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "####### Functions are defined below #######\n",
    "\n",
    "#2.     Check timestamp:\n",
    "#2a     If timestamp is older than 60s, delete tweet, jump to call calc_average_degree()\n",
    "#2b     If timestamp is newer than newest, update newest_timestamp value\n",
    "def check_and_update_timestamp( timestampToBeChecked_epoch_utc ): \n",
    "     if timestampToBeChecked_epoch_utc < global NEWEST_TIMESTAMP-60:\n",
    "        return false\n",
    "    else if timestampToBeChecked_epoch_utc > global NEWEST_TIMESTAMP:\n",
    "        global NEWEST_TIMESTAMP=timestampToBeChecked_epoch_utc;\n",
    "    return true #whether or not this was the newest timestamp or just a valid one, return true\n",
    " \n",
    "#4      Find Hashtags:NEWEST_TIMESTAMP;\n",
    "#4a     If tweet has 2 or most hashtags, check and remove all duplicates\n",
    "#4b     If only 0 or 1 hashtag remains, discard tweet\n",
    "def find_hashtags(tweet):\n",
    "    hashtags=[]\n",
    "    if (len(tweet['entities']['hashtags'])>0):\n",
    "        for tweet_entity_hashtag in tweet['entities']['hashtags']:\n",
    "            hashtags.append(tweet_entity_hashtag['text']);\n",
    "        hashtags=list(set(hashtags)) #remove duplicates. Note that this could still return just 1 hashtag\n",
    "    return hashtags\n",
    "\n",
    "#5a     Use the combination package that was imported. Eg: list(combinations(['hashtag1','hashtag2','hashtag3'],2)). This outputs a list of tuples.\n",
    "#5b     Sort each edge entry alphabetically so that we don't have the check the reverse. Do this by converting each tuple into a list and sorting\n",
    "def create_edge_entries(listOfHashtags):\n",
    "    new_list_of_tuple_edges=list(combinations(listOfHashtags,2))\n",
    "    new_list_of_edges = [sorted(element) for element in new_list_of_tuple_edges]\n",
    "    return new_list_of_edges\n",
    "\n",
    "#6      Insert each new edge entry into edge_list:\n",
    "#6a     Check that the edge doesn't already exist, if it does, update timestamp of that edge (no need to check for reverse order, because each edge entry is already sorted)\n",
    "def update_edge_list(new_list_of_edges,tweet_timestamp):\n",
    "    for new_edge_to_be_added in new_list_of_edges\n",
    "        for element in EDGE_LIST:\n",
    "            if element[1]==new_edge_to_be_added:\n",
    "                element[0]= tweet_timestamp;\n",
    "                break;\n",
    "        #looped through whole existing EDGE_LIST and didn't break out of 2nd for loop, meaning this is a new edge\n",
    "        EDGE_LIST.append([tweet_timestamp,new_edge_to_be_added])\n",
    "    return true;\n",
    "\n",
    "#7      call calc_average_degree()\n",
    "#7a     concatenate the 2 columns of nodes in the edge_list, and sum\n",
    "#7b     remove duplicates to get the number of nodes\n",
    "def calc_average_degree():\n",
    "    all_edges=getColumn(EDGE_LIST,1)\n",
    "    sumDegrees=2*len(all_edges);\n",
    "    list_of_all_nodes = set([item for sublist in all_edges for item in sublist]) #followed this: http://stackoverflow.com/questions/952914/making-a-flat-list-out-of-list-of-lists-in-python\n",
    "    num_nodes=len(list_of_all_nodes)\n",
    "    average_degree_untruncated=0.00\n",
    "    average_degree_untruncated=sumDegrees/num_nodes;\n",
    "    average_degree=float('%.2f'%(average_degree_untruncated));\n",
    "    outputFile.write(average_degree)\n",
    "    return true;\n",
    "\n",
    "#helper function for getting columns\n",
    "def getColumn(matrix, i):\n",
    "    return [row[i] for row in matrix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
